\chapter{Introduction}

\section{Context}

One of the main challenges in computer graphics is physically based rendering, the synthetic creation of images that are perceptually indistinguishable from real world views based on a geometric description of the scene, materials and light sources. There are several algorithms that try to solve this problem, although none of them is yet robust enough to handle every possible situation.

One of the first solutions, \gls{pt} proposed by \cite{Kajiya}, aims to solve this problem by tracing light transport paths starting from the camera until a light source is hit.

One improvement upon this algorithm was \gls{bdpt}, developed independently by \cite{Lafortune} and \cite{Veach}. Although with different mathematical background, the goal is to sample more light transport paths by connecting sub-paths generated from the camera and the light source. This allows for a much more efficient rendering of effects like caustics, although
effects like reflected caustics are still too difficult for a bidirectional path tracer to handle robustly.

%In an effort to improve the efficiency and robustness of light transport algorithms, \cite{Veach} proposed the adaptation of the metropolis sampling algorithm to the light transport problem. The metropolis algorithm consists in starting from any point in the function domain, we apply mutations to this point with a carefully chosen acceptance probability, and the sampling pattern will be proportional to the value of the function. In the case of rendering, the image function is the estimated incident radiance value for each pixel and the integration domain is the set of all light transport paths.

One completely different approach developed by \cite{Jensen} was instead of trying to find paths from the light source to the camera to just trace a packets of photons throughout the scene and store them in an acceleration structure referred to as Photon Map. In a second pass, the rays would start from the camera and consult the photon map in the vicinity of the intersections and calculate the expected radiance through a density estimation. Unlike all the previously presented methods, photon mapping introduces bias, that is, it may not converge to the correct result of the rendering equation. However, it is consistent, and by diminishing the search radius on the photon map and increasing the number of traced photons, the bias reduces to zero in the limit \citep{Hachisuka}.

Most recently, an attempt to combine these two approaches was proposed by \cite{Georgiev}. In this algorithm, \gls{vcm}, photon mapping and bidirectional path tracing are combined, taking advantage of each of the algorithms strong points: the high convergence rate from bidirectional path tracing and the better handling of caustics from photon mapping. These two algorithms are combined by reducing photon mapping to a path sampling technique in the path integration space formulation and combines it with bidirectional path tracing using \gls{mis}.

In spite of the differences between the different techniques, what they all have in common is the need for computational power, since all of these algorithms are based on ray tracing, a computationally expensive operation.

Although most computers nowadays contain both multicore chips with multiple \gls{cpu} and a \gls{gpu}, most commonly seen implementations only use one of these types of computational devices, and so waste useful computational power. Developing for these heterogeneous platforms, such that all different devices are effectively and efficiently used by the application, raises a number of challenges. In fact, besides all issues commonly associated with parallel processing (e.g., workload decomposition, communication overheads, load balancing), the heterogeneity of the different devices often implies maintaining different implementations for each architecture as well as dealing with separate memory address spaces.
Frameworks, such as StarPU \citep{augonnet2011starpu} and DICE \citep{Barbosa} have been proposed to alleviate the application programmer from the challenges risen by heterogeneous systems. 

\section{The Problem and its Challenges}

%In order to solve these issues there is the framework DICE, developed in the University of Texas at Austin. This framework allows an easy workload distribution as well as a memory management system. Mapping light transport algorithms to these heterogeneous systems may lead to performance improvements although no test to evaluate the suitability of these algorithms has been conducted yet.

Light transport algorithms are computationally demanding, with solutions resorting to (homogeneous) parallel computing being common. It is, however, reasonable to assume that many of these algorithms have the potential to exhibit significant efficiency levels on heterogeneous computing platforms.

With this, the main goals for this project are to evaluate the suitability of the above described path integration space rendering algorithms for parallel heterogeneous systems, such as those commonly found on current desktops, i.e., multicore \gls{cpu} and a \gls{gpu}. The DICE framework has been selected for this evaluation, because it has been developed in close cooperation with our research group and we are interested on identifying its strong and weak points, regarding both performance and usability.

One of the main challenges present when addressing heterogeneous systems is the management of multiple implementations, one for each architecture. In order to minimize this difficulty, both implementations use most of the basic structures and use specialized ray tracing frameworks, which simplifies development. Another important aspect to take into account is to minimize communication across devices, which can be costly.

Other problem specific challenges is load balancing, which is an issue with Monte Carlo methods because the workloads may be highly irregular, issue that should be addressed by the DICE scheduler.

\section{Structure of the Dissertation}

This dissertation is structured in four chapters, being the first the introduction where the problem and the main goals of the project are presented, as well as the structure of the dissertation.

The second chapter presents a background in computation light transport, namely a review of various light transport algorithms and a review on heterogeneous systems programming.

The third chapter presents the experimental work, explaining the methodologies used, the results obtained and finalizing with a discussion of those results.

The fourth and final chapter contains the conclusions, as well as the limitations of this study and possible future work.

