A heterogeneous parallel system, however, is composed by a set $D$ of $p_D$ processing devices, whose computing capabilities are not identical. We use the term {\em device} instead of processor to enhance the fact that some of these computing resources are not necessarily Central Processing Units (CPU); heterogeneous devices can also include Graphics Processing Units (GPU), Digital Signal Processors (DSP), Field Programmable Gate Arrays (FPGA), etc. Even though observed speedup can still be defined relatively to some uni-device system, optimal speedup and efficiency can no longer be defined with respect to $p_D$.

Let $T_D$ be the workload execution time on a heterogeneous system constituted by the set $D$ of devices; let $T_{\mbox{\tiny ref}}$ be the same workload execution time on a single reference device $\mbox{ref} \in D$. Then heterogeneous speedup is given by
\begin{equation}
S_h(D) = \frac{T_{\mbox{\tiny ref}}}{T_D}
\label{eq:HetSpeedUp}
\end{equation}
\cite{Chamberlain98} defined heterogeneous speedup according to equation \ref{eq:HetSpeedUp} and further suggest that the most powerful device is used as reference. If $T_d$ is the workload execution time on a single device $d \in D$, then the most powerful device is the one exhibiting the minimum $T_d$.

Optimal heterogeneous speedup, $S_h^*(D)$, can not be defined as a function of the number of devices, $p_D$, in the set $D$ of used devices, because these contribute differently to minimize execution time. \cite{Chamberlain98} express $S_h^*(D)$ as a ratio of computing rates. 

Let the computation rate for each device $d \in D$ for a given workload $W$ be defined as $R_d = \frac{W}{T_d}$. Note that $W$ is not strictly defined in terms of how it is measured or on which units it is expressed; throughout this paper it is only used to derive expressions for the presented performance related metrics. The only requirement is that this is a nominal workload, in the sense that it depends only on the used algorithm and problem size, but is independent on the number of devices $p_D$ in $D$. Intuitively, the computing rate available on the set $D$ of devices is given by the sum of the individual rates of all devices in $D$, i.e.,
\begin{equation}
R^*_D = \sum_{d \in D} R_d = W \sum_{d \in D} \frac{1}{T_d}
\label{eq:StarCapacity}
\end{equation}
\cite{Chamberlain98} define $S_h^*(D)$ as the ratio between available computing rate and the computing rate of the reference device:
\begin{equation}
S^*_h(D) = \frac{R^*_D}{R_{\mbox{\tiny ref}}} = T_{\mbox{\tiny ref}} \sum_{d \in D} \frac{1}{T_d}
\label{eq:StarHetSpeedUp}
\end{equation}
Given the definitions of heterogeneous speedup and optimal heterogeneous speedup (equations \ref{eq:HetSpeedUp} and \ref{eq:StarHetSpeedUp}), heterogeneous efficiency can thus be defined as the ratio of both
\begin{equation}
E_h(D) = \frac{S_h(D)}{S_h^*(D)} = \frac{\frac{1}{T_D}}{\sum_{d \in D} \frac{1}{T_d}}
\label{eq:HetEff}
\end{equation}
Note that neither computing rates nor workload are required to evaluate speedup or efficiency. More importantly, note that efficiency is a ratio between speedups, thus it is independent of the selected reference device; in fact, efficiency can be evaluated from the execution times without ever evaluating speedup and thus without selecting a reference device. Intuitively this is an expected result, since a measure of resources' utilization should not depend on the selection of a given reference device.